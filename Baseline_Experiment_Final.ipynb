{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Jun 25 16:12:38 2019\n",
    "\n",
    "@author: Mohamed Zeitoun\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# load basic libraries \n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>264183816548130816</td>\n",
       "      <td>positive</td>\n",
       "      <td>Gas by my house hit $3.39!!!! I\\u2019m going t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>263405084770172928</td>\n",
       "      <td>negative</td>\n",
       "      <td>Theo Walcott is still shit\\u002c watch Rafa an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>262163168678248449</td>\n",
       "      <td>negative</td>\n",
       "      <td>its not that I\\u2019m a GSP fan\\u002c i just h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>264249301910310912</td>\n",
       "      <td>negative</td>\n",
       "      <td>Iranian general says Israel\\u2019s Iron Dome c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>262682041215234048</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Tehran\\u002c Mon Amour: Obama Tried to Establi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>264229576773861376</td>\n",
       "      <td>neutral</td>\n",
       "      <td>I sat through this whole movie just for Harry ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>264105751826538497</td>\n",
       "      <td>positive</td>\n",
       "      <td>with J Davlar 11th. Main rivals are team Polan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>264094586689953794</td>\n",
       "      <td>negative</td>\n",
       "      <td>Talking about ACT\\u2019s &amp;&amp; SAT\\u2019s\\u002c d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>212392538055778304</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Why is \\\"\"Happy Valentines Day\\\"\" trending? It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>254941790757601280</td>\n",
       "      <td>negative</td>\n",
       "      <td>They may have a SuperBowl in Dallas\\u002c but ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Timestamp Sentiment  \\\n",
       "0  264183816548130816  positive   \n",
       "1  263405084770172928  negative   \n",
       "2  262163168678248449  negative   \n",
       "3  264249301910310912  negative   \n",
       "4  262682041215234048   neutral   \n",
       "5  264229576773861376   neutral   \n",
       "6  264105751826538497  positive   \n",
       "7  264094586689953794  negative   \n",
       "8  212392538055778304   neutral   \n",
       "9  254941790757601280  negative   \n",
       "\n",
       "                                               Tweet  \n",
       "0  Gas by my house hit $3.39!!!! I\\u2019m going t...  \n",
       "1  Theo Walcott is still shit\\u002c watch Rafa an...  \n",
       "2  its not that I\\u2019m a GSP fan\\u002c i just h...  \n",
       "3  Iranian general says Israel\\u2019s Iron Dome c...  \n",
       "4  Tehran\\u002c Mon Amour: Obama Tried to Establi...  \n",
       "5  I sat through this whole movie just for Harry ...  \n",
       "6  with J Davlar 11th. Main rivals are team Polan...  \n",
       "7  Talking about ACT\\u2019s && SAT\\u2019s\\u002c d...  \n",
       "8  Why is \\\"\"Happy Valentines Day\\\"\" trending? It...  \n",
       "9  They may have a SuperBowl in Dallas\\u002c but ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load train dataset into dataframe\n",
    "\n",
    "tweet_files = glob.glob(\"./twitter-201?train.txt\")\n",
    "\n",
    "# Load train dataset into dataframe\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in tweet_files:\n",
    "    df = pd.read_csv(filename, index_col=None, names=['Timestamp', 'Sentiment', 'Tweet'], sep='\\t')\n",
    "    li.append(df)\n",
    "\n",
    "tweets = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Label encoding test & training labels\n",
    "le = LabelEncoder()\n",
    "Y_train = le.fit_transform(tweets['Sentiment'])\n",
    "\n",
    "X_train = tweets['Tweet']\n",
    "\n",
    "tweets.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of different models\n",
    "model = [\n",
    "            \"CountVectorizer + Naïve Bayes Multinomial\", \n",
    "            \"TFIDFVectorizer + Naïve Bayes Multinomial\", \n",
    "            \"CountVectorizer with uni-grams and bi-grams + Naïve Bayes Multinomial\", \n",
    "            \"CountVectorizer + Logistic Regression\", \n",
    "            \"TFIDFVectorizer + Logistic Regression\", \n",
    "            \"CountVectorizer with uni-grams and bi-grams + Logistic Regression\",\n",
    "            \"TFIDFVectorizer + SVM (Linear Kernel)\",\n",
    "            \"CountVectorizer + SVM (Linear Kernel)\",\n",
    "            \"CountVectorizer with uni-grams and bi-grams + SVM (Linear Kernel)\",\n",
    "            \"TFIDFVectorizer + SVM (RBF)\",\n",
    "            \"CountVectorizer + SVM (RBF)\",\n",
    "            \"CountVectorizer with uni-grams and bi-grams + SVM (RBF)\",\n",
    "            \"CountVectorizer + Random Forest\"\n",
    "        ]\n",
    "\n",
    "#intialize the output matrix\n",
    "result = pd.DataFrame(columns=['Accuracy', 'FScore'])\n",
    "\n",
    "#Load libraries needed for classification \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "#define the 10-fold\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=1234)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer + Naïve Bayes Multinomial:\n",
      "Accuracy = 0.62\n",
      "F-Score = 0.52\n",
      "TFIDFVectorizer + Naïve Bayes Multinomial:\n",
      "Accuracy = 0.61\n",
      "F-Score = 0.44\n",
      "CountVectorizer with uni-grams and bi-grams + Naïve Bayes Multinomial:\n",
      "Accuracy = 0.63\n",
      "F-Score = 0.5\n",
      "CountVectorizer + Logistic Regression:\n",
      "Accuracy = 0.66\n",
      "F-Score = 0.61\n",
      "TFIDFVectorizer + Logistic Regression:\n",
      "Accuracy = 0.65\n",
      "F-Score = 0.57\n",
      "CountVectorizer with uni-grams and bi-grams + Logistic Regression:\n",
      "Accuracy = 0.67\n",
      "F-Score = 0.62\n",
      "TFIDFVectorizer + SVM (Linear Kernel):\n",
      "Accuracy = 0.66\n",
      "F-Score = 0.61\n",
      "CountVectorizer + SVM (Linear Kernel):\n",
      "Accuracy = 0.63\n",
      "F-Score = 0.59\n",
      "CountVectorizer with uni-grams and bi-grams + SVM (Linear Kernel):\n",
      "Accuracy = 0.66\n",
      "F-Score = 0.62\n",
      "TFIDFVectorizer + SVM (RBF):\n",
      "Accuracy = 0.43\n",
      "F-Score = 0.2\n",
      "CountVectorizer + SVM (RBF):\n",
      "Accuracy = 0.43\n",
      "F-Score = 0.2\n",
      "CountVectorizer with uni-grams and bi-grams + SVM (RBF):\n",
      "Accuracy = 0.43\n",
      "F-Score = 0.2\n",
      "CountVectorizer + Random Forest:\n",
      "Accuracy = 0.6\n",
      "F-Score = 0.52\n"
     ]
    }
   ],
   "source": [
    "#loop on each model\n",
    "for i in model:\n",
    "    if i == 'CountVectorizer + Naïve Bayes Multinomial':\n",
    "        #CountVectorizer + Naïve Bayes Multinomial pipeline\n",
    "        pipeline = Pipeline([\n",
    "        ('CountVectprizer', CountVectorizer()),\n",
    "        ('naive_bayes_Multinomial', naive_bayes.MultinomialNB())\n",
    "        ])\n",
    "    elif i == 'TFIDFVectorizer + Naïve Bayes Multinomial':\n",
    "        #TFIDFVectorizer + Naïve Bayes Multinomial pipeline\n",
    "        pipeline = Pipeline([\n",
    "        ('TFIDFVectprizer', TfidfVectorizer()),\n",
    "        ('naive_bayes_Multinomial', naive_bayes.MultinomialNB())\n",
    "        ])\n",
    "    elif i == 'CountVectorizer with uni-grams and bi-grams + Naïve Bayes Multinomial':\n",
    "        #CountVectorizer with uni-grams and bi-grams + Naïve Bayes Multinomial pipeline\n",
    "        pipeline = Pipeline([\n",
    "        ('CountVectorizer', CountVectorizer(ngram_range=(1,2))),\n",
    "        ('naive_bayes_Multinomial', naive_bayes.MultinomialNB())\n",
    "        ])\n",
    "    elif i == 'CountVectorizer + Logistic Regression':\n",
    "        #CountVectorizer + Logistic Regression pipeline\n",
    "        pipeline = Pipeline([\n",
    "        ('CountVectorizer', CountVectorizer()),\n",
    "        ('LogisticRegression', LogisticRegression())\n",
    "        ])\n",
    "    elif i == 'TFIDFVectorizer + Logistic Regression':\n",
    "        #TFIDFVectorizer + Logistic Regression pipeline\n",
    "        pipeline = Pipeline([\n",
    "        ('TFIDFVectorizer', TfidfVectorizer()),\n",
    "        ('LogisticRegression', LogisticRegression())\n",
    "        ])\n",
    "    elif i == 'CountVectorizer with uni-grams and bi-grams + Logistic Regression':\n",
    "        #CountVectorizer with uni-grams and bi-grams + Logistic Regression pipeline\n",
    "        pipeline = Pipeline([\n",
    "        ('CountVectorizer', CountVectorizer(ngram_range=(1,2))),\n",
    "        ('LogisticRegression', LogisticRegression())\n",
    "        ])\n",
    "    elif i == 'CountVectorizer + SVM (Linear Kernel)':\n",
    "        #CountVectorizer + SVM (Linear Kernel) pipeline\n",
    "        pipeline = Pipeline([\n",
    "        ('CountVectorizer', CountVectorizer()),\n",
    "        ('SVM_linear_kernel', svm.LinearSVC())\n",
    "        ])\n",
    "    elif i == 'TFIDFVectorizer + SVM (Linear Kernel)':\n",
    "        #TFIDFVectorizer + SVM (Linear Kernel) pipeline\n",
    "        pipeline = Pipeline([\n",
    "        ('TFIDFVectorizer', TfidfVectorizer()),\n",
    "        ('SVM_linear_kernel', svm.LinearSVC())\n",
    "        ])\n",
    "    elif i == 'CountVectorizer with uni-grams and bi-grams + SVM (Linear Kernel)':\n",
    "        #CountVectorizer with uni-grams and bi-grams + SVM (Linear Kernel) pipeline\n",
    "        pipeline = Pipeline([\n",
    "        ('CountVectorizer', CountVectorizer(ngram_range=(1,2))),\n",
    "        ('SVM_linear_kernel', svm.LinearSVC())\n",
    "        ])\n",
    "    elif i == 'CountVectorizer + SVM (RBF)':\n",
    "        #CountVectorizer + SVM (RBF) pipeline\n",
    "        pipeline = Pipeline([\n",
    "        ('CountVectorizer', CountVectorizer()),\n",
    "        ('SVM_RBF', svm.SVR(kernel='rbf'))\n",
    "        ])\n",
    "    elif i == 'TFIDFVectorizer + SVM (RBF)':\n",
    "        #TFIDFVectorizer + SVM (RBF) pipeline\n",
    "        pipeline = Pipeline([\n",
    "        ('TFIDFVectorizer', TfidfVectorizer()),\n",
    "        ('SVM_RBF', svm.SVR(kernel='rbf'))\n",
    "        ])\n",
    "    elif i == 'CountVectorizer with uni-grams and bi-grams + SVM (RBF)':\n",
    "        #CountVectorizer with uni-grams and bi-grams + SVM (RBF) pipeline\n",
    "        pipeline = Pipeline([\n",
    "        ('CountVectorizer', CountVectorizer(ngram_range=(1,2))),\n",
    "        ('SVM_RBF', svm.SVR(kernel='rbf'))\n",
    "        ])\n",
    "    elif i == 'CountVectorizer + Random Forest':\n",
    "        #CountVectorizer + Random Forest pipeline\n",
    "        pipeline = Pipeline([\n",
    "        ('CountVectorizer', CountVectorizer()),\n",
    "        ('RandomForest', RandomForestClassifier())\n",
    "        ])\n",
    "    else:\n",
    "        print(\"ERROR: Model Not Supported!\")\n",
    "        continue\n",
    "           \n",
    "    #intialize the mean absolute error counter\n",
    "    accuracy = 0.0\n",
    "    Fscore = 0.0\n",
    "    \n",
    "    #K-fold cross validation\n",
    "    for fold, (train_index, val_index) in enumerate(kfold.split(X_train, Y_train)):\n",
    "        train_x, train_y = X_train.iloc[train_index], Y_train[train_index]\n",
    "        val_x, val_y = X_train.iloc[val_index], Y_train[val_index]\n",
    "        \n",
    "        #Model fit & Prediction\n",
    "        pipeline.fit(train_x, train_y)\n",
    "        predictions = pipeline.predict(val_x)\n",
    "        \n",
    "        #Calculate the Accuracy & F-Score \n",
    "        accuracy += metrics.accuracy_score(val_y, predictions.round())\n",
    "        Fscore += metrics.f1_score(val_y, predictions.round(), average='macro')\n",
    "        \n",
    "    accuracy /= kfold.get_n_splits()\n",
    "    Fscore /= kfold.get_n_splits()\n",
    "    \n",
    "    print(i + \":\")\n",
    "    print(\"Accuracy = {}\".format(accuracy.round(2)))\n",
    "    print(\"F-Score = {}\".format(Fscore.round(2)))\n",
    "    \n",
    "#    scores = cross_val_score(pipeline, X_train, Y_train, cv=10 )\n",
    "#    fscores = cross_val_score(pipeline, X_train, Y_train, cv=10, scoring='f1_macro')\n",
    "#    print(i + \":\")\n",
    "#    print(\"Accuracy = {}\".format(scores.mean()))\n",
    "#    print(\"F-Score = {}\".format(fscores.mean()))\n",
    "    \n",
    "    result.loc[i,'Accuracy']=accuracy.round(2)\n",
    "    result.loc[i,'FScore']=Fscore.round(2)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>FScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CountVectorizer with uni-grams and bi-grams + Logistic Regression</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountVectorizer with uni-grams and bi-grams + SVM (Linear Kernel)</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountVectorizer + Logistic Regression</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TFIDFVectorizer + SVM (Linear Kernel)</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountVectorizer + SVM (Linear Kernel)</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TFIDFVectorizer + Logistic Regression</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountVectorizer + Naïve Bayes Multinomial</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountVectorizer + Random Forest</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountVectorizer with uni-grams and bi-grams + Naïve Bayes Multinomial</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TFIDFVectorizer + Naïve Bayes Multinomial</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TFIDFVectorizer + SVM (RBF)</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountVectorizer + SVM (RBF)</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountVectorizer with uni-grams and bi-grams + SVM (RBF)</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Accuracy FScore\n",
       "CountVectorizer with uni-grams and bi-grams + L...     0.67   0.62\n",
       "CountVectorizer with uni-grams and bi-grams + S...     0.66   0.62\n",
       "CountVectorizer + Logistic Regression                  0.66   0.61\n",
       "TFIDFVectorizer + SVM (Linear Kernel)                  0.66   0.61\n",
       "CountVectorizer + SVM (Linear Kernel)                  0.63   0.59\n",
       "TFIDFVectorizer + Logistic Regression                  0.65   0.57\n",
       "CountVectorizer + Naïve Bayes Multinomial              0.62   0.52\n",
       "CountVectorizer + Random Forest                         0.6   0.52\n",
       "CountVectorizer with uni-grams and bi-grams + N...     0.63    0.5\n",
       "TFIDFVectorizer + Naïve Bayes Multinomial              0.61   0.44\n",
       "TFIDFVectorizer + SVM (RBF)                            0.43    0.2\n",
       "CountVectorizer + SVM (RBF)                            0.43    0.2\n",
       "CountVectorizer with uni-grams and bi-grams + S...     0.43    0.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(result.sort_values(by='FScore', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
